{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd1be4f1-92ee-4f92-a8d3-cec66fe2d43e",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd1374f1-5dad-4cc5-94e5-a5d1c0244b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import json\n",
    "import os\n",
    "import logging  # To log errors or missing files\n",
    "from collections import namedtuple\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f99a5446-1b21-431e-b40b-b588e13ebb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configures basic logging to print informational messages\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56dec583-c3f0-45a9-967e-f3ceab3489f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_file = \"annotations.json\"\n",
    "image_folder = \"coco-nyaptola/images\"\n",
    "\n",
    "# Convert to absolute paths for reliable file access\n",
    "annotation_file = os.path.abspath(annotation_file)\n",
    "image_folder = os.path.abspath(image_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca214c27-88e7-4b57-85b6-518ed0795e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "ImageData = namedtuple('ImageData',['image','target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27fbd3e1-cfa0-42c9-9bea-dcdf5aab83b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path_str = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3624599e-7ea9-42e6-b8bf-020fbc65399f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load annotations from a COCO JSON file\n",
    "def load_annotations(annotation_file):\n",
    "    with open(annotation_file, 'r') as f:\n",
    "        annotations = json.load(f) #loaded annotations dictionary\n",
    "    return annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6bbcce3c-8471-442a-be8d-b99658c2cadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_and_annotations(image_path, annotations):\n",
    "    # Initialize an empty image path string\n",
    "    image_path_str = \"\"\n",
    "\n",
    "    try:\n",
    "        # Ensure that the input is a TensorFlow tensor\n",
    "        if isinstance(image_path, tf.Tensor):\n",
    "            # Convert Tensor to Python string for file operations\n",
    "            image_path_str = image_path.numpy().decode(\"utf-8\")\n",
    "        else:\n",
    "            raise ValueError(\"Expected TensorFlow tensor for image path.\")\n",
    "\n",
    "        # Read the image from the file path\n",
    "        image = tf.io.decode_png(tf.io.read_file(image_path_str), channels=3)\n",
    "\n",
    "        # Get the image information from the annotations\n",
    "        image_info = next(\n",
    "            (img for img in annotations['images'] if os.path.basename(image_path_str) in img.values()),\n",
    "            None\n",
    "        )\n",
    "\n",
    "        if not image_info:\n",
    "            raise ValueError(f\"Image '{image_path_str}' not found in annotations.\")\n",
    "\n",
    "        image_id = image_info['id']\n",
    "\n",
    "        # Get bounding boxes and classes for the image\n",
    "        bboxes = [\n",
    "            ann['bbox'] for ann in annotations['annotations']\n",
    "            if ann['image_id'] == image_id\n",
    "        ]\n",
    "        classes = [\n",
    "            ann['category_id'] for ann in annotations['annotations']\n",
    "            if ann['image_id'] == image_id\n",
    "        ]\n",
    "\n",
    "        return image, {'boxes': bboxes, 'classes': classes}\n",
    "\n",
    "    except Exception as e:\n",
    "        # Log the error and return default values\n",
    "        logging.warning(f\"Error loading image: {e}\")\n",
    "        return tf.zeros([1, 1, 3], dtype=tf.uint8), {'boxes': [], 'classes': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "06e1ad4e-c3f8-4d6f-941d-179599ce5fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader(annotation_file, image_folder):\n",
    "    # Load annotations from COCO-format JSON file\n",
    "    annotations = load_annotations(annotation_file)\n",
    "\n",
    "    # List of image file paths from annotations\n",
    "    image_files = [\n",
    "        tf.convert_to_tensor(os.path.join(image_folder, img[0]), dtype=tf.string)\n",
    "        for img in annotations[0]\n",
    "    ]\n",
    "\n",
    "    def load_data(image_file):\n",
    "        image, target = load_image_and_annotations(image_file, annotations)\n",
    "\n",
    "        # Ensure bounding boxes and classes have expected shapes\n",
    "        bboxes = target['boxes']\n",
    "        classes = target['classes']\n",
    "\n",
    "        if len(bboxes) == 0:\n",
    "            bboxes = tf.zeros((1, 4), dtype=tf.float32)  # Safe empty bounding box\n",
    "        if len(classes) == 0:\n",
    "            classes = tf.zeros((1,), dtype=tf.int32)  # Safe empty class array\n",
    "\n",
    "        return image, {'boxes': bboxes, 'classes': classes}\n",
    "\n",
    "    # Create a dataset with bounding boxes and classes\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(image_files).map(load_data)\n",
    "\n",
    "    # Add debugging information to ensure dataset is correct\n",
    "    for data in dataset.take(5):\n",
    "        image, target = data\n",
    "        print(\"Image shape:\", image.shape)  # Verify image shapes\n",
    "        print(\"Bounding boxes shape:\", target['boxes'].shape)\n",
    "        print(\"Classes shape:\", target['classes'].shape)\n",
    "\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ca1eff98-b24f-4d3c-b008-e1234800161f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images in annotations: 3\n",
      "Annotations count: 3\n"
     ]
    }
   ],
   "source": [
    "annotations = load_annotations(\"annotations.json\")\n",
    "\n",
    "print(\"Images in annotations:\", len(annotations[0]))  # Ensure expected number of images\n",
    "print(\"Annotations count:\", len(annotations[1]))  # Ensure expected number of annotations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a91fa9c4-4f4a-443c-bcc9-e356076d3943",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Error loading image: 'SymbolicTensor' object has no attribute 'numpy'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: (1, 1, 3)\n",
      "Bounding boxes shape: (1, 4)\n",
      "Classes shape: (1,)\n",
      "Image shape: (1, 1, 3)\n",
      "Bounding boxes shape: (1, 4)\n",
      "Classes shape: (1,)\n",
      "Image shape: (1, 1, 3)\n",
      "Bounding boxes shape: (1, 4)\n",
      "Classes shape: (1,)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = data_loader(annotation_file, image_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4aa15438-f878-4f22-8037-bda36d285231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.data.ops.map_op._MapDataset'>\n",
      "(TensorSpec(shape=(1, 1, 3), dtype=tf.uint8, name=None), {'boxes': TensorSpec(shape=(1, 4), dtype=tf.float32, name=None), 'classes': TensorSpec(shape=(1,), dtype=tf.int32, name=None)})\n"
     ]
    }
   ],
   "source": [
    "# prints the type of train_dataset. \n",
    "print(type(train_dataset))  # Should be <class 'tensorflow.python.data.ops.dataset_ops.DatasetV2'>\n",
    "print(train_dataset.element_spec)  # Should reflect the expected structure of elements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "49f7f093-42bb-4972-b6cf-c060a12e6af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: (1, 1, 3)\n",
      "target: {'boxes': <tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[0., 0., 0., 0.]], dtype=float32)>, 'classes': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([0])>}\n",
      "Image shape: (1, 1, 3)\n",
      "target: {'boxes': <tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[0., 0., 0., 0.]], dtype=float32)>, 'classes': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([0])>}\n",
      "Image shape: (1, 1, 3)\n",
      "target: {'boxes': <tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[0., 0., 0., 0.]], dtype=float32)>, 'classes': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([0])>}\n"
     ]
    }
   ],
   "source": [
    "for data in train_dataset.take(5):  # Adjust the number of samples\n",
    "    image, target = data\n",
    "    print(\"Image shape:\", image.shape)  # Check the image shape and other attributes\n",
    "    print(\"target:\", target)  # Check bounding boxes and classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af83506b-c15e-46f4-aeab-29fb710c759a",
   "metadata": {},
   "source": [
    "## Data Visualization and Batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3ae32dbc-6022-4bbb-b31c-763b5646a706",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import keras\n",
    "import keras_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ad12d8cd-22a3-4819-b60b-f44fe28dd97f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.map_op._MapDataset"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d4ae675b-10c8-4b1f-ae28-21f1223f19f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of json files, hardcoded for now\n",
    "length = 100\n",
    "SPLIT_RATIO = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5cc70f8f-0e19-4d0d-bf4f-266ad0f5b875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the number of validation samples\n",
    "num_val = int(length * SPLIT_RATIO)\n",
    " \n",
    "# Split the dataset into train and validation sets\n",
    "val_data = train_dataset.take(num_val)\n",
    "train_data = train_dataset.skip(num_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "30fd4920-e6e9-4c8f-8cb9-30d042065e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_dataset(inputs, value_range, rows, cols, bounding_box_format, class_mapping):\n",
    "    # Extract a single batch from the dataset\n",
    "    inputs = next(iter(inputs.take(1)))\n",
    "\n",
    "    image = inputs[0]\n",
    "    bounding_box_info = inputs[1]\n",
    "\n",
    "    # Convert to NumPy arrays\n",
    "    bounding_boxes = bounding_box_info[\"boxes\"].numpy()\n",
    "    classes = bounding_box_info[\"classes\"].numpy()\n",
    "\n",
    "    # Ensure the image is a batch of images\n",
    "    if len(image.shape) == 3:  # If it's a single image\n",
    "        image = tf.expand_dims(image, axis=0)  # Convert to a batch of 1\n",
    "\n",
    "    bounding_box_data = {\"boxes\": bounding_boxes, \"classes\": classes}\n",
    "\n",
    "    # Visualization function call with the corrected shape\n",
    "    visualization.plot_bounding_box_gallery(\n",
    "        image.numpy(),  # Convert image to NumPy with proper shape\n",
    "        value_range=value_range,\n",
    "        rows=rows,\n",
    "        cols=cols,\n",
    "        y_true=bounding_box_data,  # Pass bounding box data\n",
    "        scale=5,\n",
    "        font_scale=0.7,\n",
    "        bounding_box_format=bounding_box_format,\n",
    "        class_mapping=class_mapping,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "69bb1a69-c102-4d5e-ab14-f7bb70438a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_mapping = { 0: \"nyatapola\" }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "09d43f83-655e-4254-9b54-f20aa12c28bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfRangeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\object_detection\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:809\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    808\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 809\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    810\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOutOfRangeError:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\object_detection\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:772\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    771\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecution_mode(context\u001b[38;5;241m.\u001b[39mSYNC):\n\u001b[1;32m--> 772\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator_get_next\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    773\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    774\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    775\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_shapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    777\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    778\u001b[0m     \u001b[38;5;66;03m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\object_detection\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:3086\u001b[0m, in \u001b[0;36miterator_get_next\u001b[1;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[0;32m   3085\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 3086\u001b[0m   \u001b[43m_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from_not_ok_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3087\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_FallbackException:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\object_detection\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:5983\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   5982\u001b[0m e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m-> 5983\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mOutOfRangeError\u001b[0m: {{function_node __wrapped__IteratorGetNext_output_types_3_device_/job:localhost/replica:0/task:0/device:CPU:0}} End of sequence [Op:IteratorGetNext] name: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[91], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mvisualize_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounding_box_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mxyxy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m255\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_mapping\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mclass_mapping\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[89], line 3\u001b[0m, in \u001b[0;36mvisualize_dataset\u001b[1;34m(inputs, value_range, rows, cols, bounding_box_format, class_mapping)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvisualize_dataset\u001b[39m(inputs, value_range, rows, cols, bounding_box_format, class_mapping):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# Extract a single batch from the dataset\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     image \u001b[38;5;241m=\u001b[39m inputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      6\u001b[0m     bounding_box_info \u001b[38;5;241m=\u001b[39m inputs[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\object_detection\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:811\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    809\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_internal()\n\u001b[0;32m    810\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOutOfRangeError:\n\u001b[1;32m--> 811\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[1;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "visualize_dataset(\n",
    "    train_data, bounding_box_format=\"xyxy\", value_range=(0, 255), rows=2, cols=2, class_mapping = class_mapping\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6265569-b228-4753-8b2b-97d3cf71a22a",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b3a7fe-d636-4814-b3e8-30af400d95ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
