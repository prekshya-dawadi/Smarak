{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4654cae-4cc6-4229-9513-43038031ee31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "from ultralytics.data.augment import Albumentations\n",
    "from ultralytics.utils import LOGGER, colorstr\n",
    "from pathlib import Path\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a365bf9a-2f6d-4b35-a0a8-68d2f6ef9a08",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ca89519-0a34-466e-85bc-1742e1bb02b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"hyperparameters.yaml\") as f:\n",
    "    hyp = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f665b27-358b-4699-9f60-10a8dbafd303",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'config.yaml'  \n",
    "cfg = 'yolov8.yaml'\n",
    "weights = 'runs/detect/train21/weights/best.pt'  \n",
    "epochs = 5 \n",
    "batch_size = 16  \n",
    "img_size = 640  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9317be6f-8497-4df4-b42b-6b2b5ba69912",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = YOLO(\"yolov8n.yaml\").load(Path(\"runs/detect/train21/weights/best.pt\"))\n",
    "model = YOLO(\"runs/detect/train21/weights/best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc218c32-a8ae-4cd8-a88f-397403845b6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = model.train(\n",
    "    data=data,\n",
    "    epochs=epochs,\n",
    "    batch=batch_size,\n",
    "    imgsz=img_size,\n",
    "    # hyp=hyp,\n",
    "    # device=0, # Use GPU if available\n",
    "    # amp=True # Mixed Precision Training\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2672056f-5902-4fa4-8c0c-236d7609a0a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x416 1 goldengate, 128.8ms\n",
      "Speed: 0.0ms preprocess, 128.8ms inference, 513.6ms postprocess per image at shape (1, 3, 640, 416)\n"
     ]
    }
   ],
   "source": [
    "prediction = model([\"https://c8.alamy.com/comp/T00N4G/golden-gate-bhaktapur-nepal-T00N4G.jpg\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d36d5841-d2eb-4de4-bbc4-59d52c95d5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pred in prediction:\n",
    "    boxes = pred.boxes\n",
    "    probs = pred.probs\n",
    "    pred.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fad3e0-9a46-43ed-b646-e5830a69ef0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.val(data='config.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243c190f-825f-4fcb-9b5c-9252aa6f3540",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86a014d-5aaf-45bc-95e4-89fb5d3f46a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('initial_train.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abea97bf-eb9d-480a-8988-dee41cd07eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.18  Python-3.9.19 torch-2.3.0+cpu CPU (11th Gen Intel Core(TM) i5-1135G7 2.40GHz)\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'runs\\detect\\train21\\weights\\best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 6, 8400) (5.9 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.13.1...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/calibration_image_sample_data_20x128x128x3_float32.npy.zip to 'calibration_image_sample_data_20x128x128x3_float32.npy.zip'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 1.11M/1.11M [00:00<00:00, 3.45MB/s]\n",
      "Unzipping calibration_image_sample_data_20x128x128x3_float32.npy.zip to D:\\Projects\\DL\\MonumentDetection\\DL\\ultralytics\\calibration_"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.16.0 opset 17...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mONNX:\u001b[0m simplifying with onnxsim 0.4.36...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  2.2s, saved as 'runs\\detect\\train21\\weights\\best.onnx' (11.7 MB)\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting TFLite export with onnx2tf 1.17.5...\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m export success  16.5s, saved as 'runs\\detect\\train21\\weights\\best_saved_model' (29.5 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m starting export with tensorflow 2.13.1...\n",
      "\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m export success  0.0s, saved as 'runs\\detect\\train21\\weights\\best_saved_model\\best_float32.tflite' (11.7 MB)\n",
      "\n",
      "Export complete (18.6s)\n",
      "Results saved to \u001b[1mD:\\Projects\\DL\\MonumentDetection\\DL\\ultralytics\\runs\\detect\\train21\\weights\u001b[0m\n",
      "Predict:         yolo predict task=detect model=runs\\detect\\train21\\weights\\best_saved_model\\best_float32.tflite imgsz=640  \n",
      "Validate:        yolo val task=detect model=runs\\detect\\train21\\weights\\best_saved_model\\best_float32.tflite imgsz=640 data=/content/config.yaml  \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'runs\\\\detect\\\\train21\\\\weights\\\\best_saved_model\\\\best_float32.tflite'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.export(format=\"tflite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d55ebff-23d0-413c-b580-89fd0d102478",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
