{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54af74ac-8a0b-4c53-889d-3ce908651b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "from ultralytics.data.augment import Albumentations\n",
    "from ultralytics.utils import LOGGER, colorstr\n",
    "from pathlib import Path\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e93142ce-1590-40ed-9129-3e3533aa98c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transferred 319/355 items from pretrained weights\n"
     ]
    }
   ],
   "source": [
    "model = YOLO(\"yolov8n.yaml\").load(Path(\"runs/detect/train6/weights/best.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "58704d21-61d7-431d-92bf-87bb58789c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 3 0s, 2 2s, 1 3, 2 4s, 2 5s, 2 8s, 3 9s, 10 10s, 2 11s, 4 12s, 9 13s, 6 14s, 1 17, 2 18s, 6 19s, 1 20, 7 21s, 9 22s, 4 23s, 2 25s, 3 26s, 2 27s, 3 29s, 2 30s, 6 31s, 3 33s, 2 34s, 5 36s, 7 37s, 2 40s, 6 41s, 5 42s, 4 43s, 7 44s, 2 45s, 3 46s, 1 48, 4 49s, 1 50, 1 51, 2 52s, 2 53s, 4 55s, 1 56, 2 57s, 2 58s, 5 59s, 4 61s, 1 62, 6 63s, 3 64s, 7 65s, 1 66, 1 67, 1 69, 3 70s, 1 72, 4 73s, 1 74, 4 76s, 6 77s, 2 78s, 174.6ms\n",
      "1: 640x640 1 3, 1 4, 2 5s, 1 9, 6 10s, 4 11s, 5 12s, 4 13s, 2 14s, 4 16s, 3 17s, 3 19s, 2 20s, 12 21s, 15 22s, 2 23s, 3 26s, 3 27s, 5 29s, 3 34s, 10 36s, 5 37s, 10 41s, 3 42s, 2 43s, 2 44s, 5 45s, 1 46, 1 48, 11 49s, 1 50, 5 52s, 4 53s, 1 54, 2 55s, 2 56s, 2 57s, 2 58s, 6 59s, 9 61s, 5 63s, 20 65s, 1 66, 2 67s, 6 69s, 1 70, 1 73, 1 74, 8 76s, 174.6ms\n",
      "2: 640x640 1 1, 1 2, 1 7, 1 8, 2 9s, 15 10s, 22 13s, 1 16, 1 17, 4 18s, 5 19s, 2 20s, 11 21s, 3 22s, 1 24, 1 26, 1 27, 2 29s, 8 31s, 1 34, 3 36s, 4 37s, 2 40s, 3 41s, 4 42s, 15 43s, 2 44s, 1 46, 4 48s, 3 49s, 4 50s, 1 51, 1 52, 4 55s, 5 56s, 1 59, 2 60s, 2 61s, 4 64s, 5 65s, 6 67s, 1 68, 6 69s, 1 70, 1 72, 4 76s, 3 77s, 4 78s, 174.6ms\n",
      "3: 640x640 1 1, 1 2, 1 7, 1 8, 2 9s, 15 10s, 22 13s, 1 16, 1 17, 4 18s, 5 19s, 2 20s, 11 21s, 3 22s, 1 24, 1 26, 1 27, 2 29s, 8 31s, 1 34, 3 36s, 4 37s, 2 40s, 3 41s, 4 42s, 15 43s, 2 44s, 1 46, 4 48s, 3 49s, 4 50s, 1 51, 1 52, 4 55s, 5 56s, 1 59, 2 60s, 2 61s, 4 64s, 5 65s, 6 67s, 1 68, 6 69s, 1 70, 1 72, 4 76s, 3 77s, 4 78s, 174.6ms\n",
      "Speed: 3.7ms preprocess, 174.6ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict([\"dataset2/train/images/0f2b5ba0-image_485.png\", \"dataset2/train/images/6a6eb3c5-IMG_1906.JPG\", \"dataset2/train/images/augmented_0_b5b728ea-image_83.png\", \"dataset2/train/images/augmented_0_b5b728ea-image_83.png\"], conf=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3d496f61-f6c2-4649-8ac2-7d13b71b939f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pred in prediction:\n",
    "    boxes = pred.boxes\n",
    "    probs = pred.probs\n",
    "    pred.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95dfd0d-2e46-43ed-b6b0-19a7a04230c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
