{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38121443-a5d6-4c86-a54b-d8ddff6fa289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Projects\\\\DL\\\\MonumentDetection\\\\DL'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "cfa141a4-a900-4d62-b14e-dc21511dffe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import math\n",
    "import keras_cv\n",
    "import matplotlib.pyplot as plt\n",
    "import keras_cv.visualization as visualization\n",
    "import cv2\n",
    "import keras\n",
    "from keras_cv import models, losses, callbacks\n",
    "import keras_cv.losses as losses\n",
    "from keras_cv.models import YOLOV8Detector\n",
    "import matplotlib.patches as patches\n",
    "from tensorflow import data as tf_data\n",
    "import tensorflow_datasets as tfds\n",
    "import keras\n",
    "import keras_cv\n",
    "import numpy as np\n",
    "from keras_cv import bounding_box\n",
    "import os\n",
    "from keras_cv import visualization\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5f652e-2981-402a-bb39-daef954b47a7",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "792411ba-376d-4537-8857-2ea473b2cffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (640, 640)  # Input size for YOLOv8\n",
    "BATCH_SIZE = 3  # Number of samples per batch\n",
    "NUM_CLASSES = 1  # Example number of classes, adjust as needed\n",
    "BOUNDING_BOX_FORMAT = \"xywh\"  # YOLO bounding box format\n",
    "PAD_TO_ASPECT_RATIO = True  # To maintain aspect ratio when resizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "69756c5b-db71-4a0d-8313-7b6ca82c4a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to the datasets\n",
    "TRAIN_IMAGES_DIR = Path(\"dataset/train/images/\")\n",
    "TRAIN_LABELS_DIR = Path(\"dataset/train/labels/\")\n",
    "\n",
    "VAL_IMAGES_DIR = Path(\"dataset/val/images/\")\n",
    "VAL_LABELS_DIR = Path(\"dataset/val/labels/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "ee882b3d-88c7-4758-a8a9-f79cff9fea6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(408, 612, 3)\n",
      "(338, 509, 3)\n",
      "(960, 545, 3)\n",
      "(612, 408, 3)\n",
      "(408, 612, 3)\n",
      "(413, 612, 3)\n",
      "(612, 408, 3)\n",
      "(612, 408, 3)\n",
      "(406, 612, 3)\n",
      "(612, 343, 3)\n",
      "(360, 640, 3)\n",
      "(612, 408, 3)\n",
      "(407, 612, 3)\n",
      "(667, 1000, 3)\n",
      "(612, 408, 3)\n",
      "(408, 612, 3)\n",
      "(612, 476, 3)\n",
      "(612, 408, 3)\n",
      "(612, 392, 3)\n",
      "(408, 612, 3)\n",
      "(612, 408, 3)\n",
      "(400, 612, 3)\n",
      "(360, 540, 3)\n",
      "(330, 660, 3)\n",
      "(612, 416, 3)\n",
      "(408, 612, 3)\n",
      "(612, 392, 3)\n",
      "(408, 612, 3)\n",
      "(338, 507, 3)\n",
      "(612, 398, 3)\n",
      "(612, 408, 3)\n",
      "(612, 408, 3)\n",
      "(612, 408, 3)\n",
      "(408, 612, 3)\n",
      "(612, 408, 3)\n",
      "(612, 408, 3)\n",
      "(408, 612, 3)\n",
      "(612, 408, 3)\n",
      "(408, 612, 3)\n",
      "(720, 960, 3)\n",
      "(339, 509, 3)\n",
      "(612, 413, 3)\n",
      "(360, 640, 3)\n",
      "(408, 612, 3)\n",
      "(360, 458, 3)\n",
      "(408, 612, 3)\n",
      "(490, 612, 3)\n",
      "(612, 406, 3)\n",
      "(612, 408, 3)\n",
      "(459, 612, 3)\n",
      "(338, 509, 3)\n",
      "(408, 612, 3)\n",
      "(408, 612, 3)\n",
      "(640, 516, 3)\n",
      "(400, 612, 3)\n",
      "(339, 509, 3)\n",
      "(408, 612, 3)\n",
      "(428, 612, 3)\n",
      "(612, 408, 3)\n",
      "(612, 408, 3)\n",
      "(612, 392, 3)\n",
      "(612, 591, 3)\n",
      "(408, 612, 3)\n",
      "(612, 408, 3)\n",
      "(612, 408, 3)\n",
      "(408, 612, 3)\n",
      "(438, 612, 3)\n",
      "(667, 1000, 3)\n",
      "(612, 408, 3)\n",
      "(408, 612, 3)\n",
      "(612, 406, 3)\n",
      "(360, 540, 3)\n",
      "(900, 600, 3)\n",
      "(360, 539, 3)\n",
      "(408, 612, 3)\n",
      "(344, 612, 3)\n",
      "(612, 464, 3)\n",
      "(612, 408, 3)\n",
      "(459, 612, 3)\n",
      "(408, 612, 3)\n"
     ]
    }
   ],
   "source": [
    "# Assuming TRAIN_IMAGES_DIR is a directory containing image file paths\n",
    "for filename in os.listdir(TRAIN_IMAGES_DIR):\n",
    "    image_path = TRAIN_IMAGES_DIR / filename  # Construct the full image path\n",
    "    if not image_path.exists():\n",
    "        print(f\"File does not exist: {image_path}\")\n",
    "        continue\n",
    "\n",
    "    image = cv2.imread(str(image_path))  # Convert to string if necessary for cv2.imread\n",
    "    \n",
    "    if image is None:\n",
    "        print(f\"Failed to read image: {image_path}\")\n",
    "    else:\n",
    "        print(image.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "e6680462-dfd2-4fb5-ae1d-5a65f384e102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load YOLO annotations\n",
    "def load_yolo_annotations(label_path, image_size):\n",
    "    annotations = []\n",
    "    with open(label_path, 'r') as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split(\" \")\n",
    "            if len(parts) != 5:\n",
    "                continue  # Skip lines that don't match expected format\n",
    "\n",
    "            class_id = int(parts[0])\n",
    "            x_center = float(parts[1])\n",
    "            y_center = float(parts[2])\n",
    "            width = float(parts[3])\n",
    "            height = float(parts[4])\n",
    "\n",
    "            # Convert normalized \"xywh\" to pixel-based \"xyxy\" format\n",
    "            x_min = (x_center - width / 2) * image_size[0]\n",
    "            y_min = (y_center - height / 2) * image_size[1]\n",
    "            x_max = (x_center + width / 2) * image_size[0]\n",
    "            y_max = (y_center + height / 2) * image_size[1]\n",
    "\n",
    "            annotations.append([x_min, y_min, x_max, y_max, class_id])\n",
    "\n",
    "    return np.array(annotations, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "3cb9598a-87bd-4e6e-bc15-fb359fa7d245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load image and corresponding annotations\n",
    "def load_sample(image_path, labels_dir):\n",
    "    image_path_str = tf.keras.backend.get_value(image_path).decode(\"utf-8\")  # Convert tensor to string\n",
    "    image = Image.open(image_path_str).resize(IMAGE_SIZE)  # Resize to 640x640\n",
    "    image = np.array(image) / 255.0  # Normalize\n",
    "    \n",
    "    # Construct the label path and validate its existence\n",
    "    image_stem = Path(image_path_str).stem\n",
    "    label_path = os.path.join(labels_dir, image_stem + \".txt\")\n",
    "\n",
    "    if not os.path.isfile(label_path):\n",
    "        raise FileNotFoundError(f\"Label file not found: {label_path}\")\n",
    "\n",
    "    # Load YOLO annotations\n",
    "    annotations = load_yolo_annotations(label_path, IMAGE_SIZE)  # Load annotations\n",
    "    return image, annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "6054bcf6-104d-471c-9677-629910b78576",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_resizing(image, annotations):\n",
    "    print(f\"Image shape: {image.shape}, Annotations: {annotations}\")\n",
    "    resized_image = tf.image.resize(image, [IMAGE_SIZE[0], IMAGE_SIZE[1]])\n",
    "    return resized_image, annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "26b53297-b762-4c3c-b138-3c4e4fbc9249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to count elements in a dataset\n",
    "def count_elements(dataset):\n",
    "    return dataset.cardinality().numpy()\n",
    "\n",
    "# Check if the dataset is empty\n",
    "def is_dataset_empty(dataset):\n",
    "    return count_elements(dataset) <= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "a5dffbdd-4c1f-44b6-83f6-0814bdad0af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to separate class IDs from bounding box coordinates\n",
    "def extract_bounding_box_info(bounding_boxes_raw):\n",
    "    # Check if the last dimension has five elements\n",
    "    if bounding_boxes_raw.shape[-1] == 5:\n",
    "        # Extract the class ID (last element) and bounding box coordinates\n",
    "        class_ids = bounding_boxes_raw[..., -1]  # The last element is the class ID\n",
    "        bounding_boxes = bounding_boxes_raw[..., :-1]  # The rest is the bounding box coordinates\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected bounding box shape: {bounding_boxes_raw.shape}\")\n",
    "    return bounding_boxes, class_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "2d728cb6-0d48-4513-aeeb-f5ab25b53bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to normalize image data\n",
    "def normalize_image_data(image):\n",
    "    # Convert TensorFlow tensor to NumPy array\n",
    "    image = image.numpy()  # Explicit conversion\n",
    "    # If data is in float format, scale to [0, 255]\n",
    "    if image.dtype == np.float32 or image.dtype == np.float64:\n",
    "        image = (image * 255).astype(np.uint8)  # Scale to [0, 255]\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "579c499c-da86-4bfe-a6b9-e1dfd4b3d8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert from BGR to RGB if needed\n",
    "def ensure_rgb_format(image):\n",
    "    # If the image appears incorrect, try converting BGR to RGB\n",
    "    if image.shape[-1] == 3:  # Assuming three channels (RGB or BGR)\n",
    "        return image[..., ::-1]  # Reverse the color channels to convert BGR to RGB\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "ca6ada37-47ce-4d27-8138-4027ad1baaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_empty_annotations(image, annotations):\n",
    "    # Assuming annotations is a list of bounding boxes\n",
    "    if len(annotations) == 0:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "cafe9096-22f6-41c5-81e4-57ad239480c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_annotations(image, annotations, max_annotations=5):\n",
    "    num_annotations = tf.shape(annotations)[0]\n",
    "    annotations = tf.reshape(annotations, [num_annotations, 5])\n",
    "\n",
    "    padding = [[0, max_annotations - num_annotations], [0, 0]]\n",
    "    annotations = tf.pad(annotations, padding, constant_values=-1)\n",
    "\n",
    "    boxes = annotations[:, :4]\n",
    "    classes = tf.expand_dims(annotations[:, 4], axis=-1)\n",
    "    \n",
    "    return image, {'boxes': boxes, 'classes': classes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "c29aff6b-e9b5-4cbe-b980-908f35af6efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader(images_dir, labels_dir, batch_size):\n",
    "    image_paths = list(Path(images_dir).rglob(\"*.jpg\")) + list(Path(images_dir).rglob(\"*.png\"))\n",
    "\n",
    "    if len(image_paths) == 0:\n",
    "        raise ValueError(f\"No images found in {images_dir}. Check your dataset path.\")\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices([str(p) for p in image_paths])\n",
    "\n",
    "    def load_sample_with_shape(image_path):\n",
    "        image, annotations = tf.py_function(\n",
    "            lambda y: load_sample(y, labels_dir),\n",
    "            [image_path],\n",
    "            [tf.float32, tf.float32]\n",
    "        )\n",
    "        image.set_shape(IMAGE_SIZE + (3,))\n",
    "        annotations.set_shape([None, 5])\n",
    "        return image, annotations\n",
    "\n",
    "    dataset = dataset.map(load_sample_with_shape, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "    def resize_with_shape(image, annotations):\n",
    "        image, annotations = tf.py_function(\n",
    "            func=lambda img, ann: inference_resizing(img, ann),\n",
    "            inp=[image, annotations],\n",
    "            Tout=[tf.float32, tf.float32]\n",
    "        )\n",
    "        image.set_shape([224, 224, 3])\n",
    "        annotations.set_shape([None, 5])\n",
    "        return image, annotations\n",
    "\n",
    "    dataset = dataset.map(resize_with_shape, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "    def normalize_with_shape(image, annotations):\n",
    "        image, annotations = tf.py_function(\n",
    "            func=lambda img, ann: (normalize_image_data(img), ann),\n",
    "            inp=[image, annotations],\n",
    "            Tout=[tf.float32, tf.float32]\n",
    "        )\n",
    "        image.set_shape([224, 224, 3])\n",
    "        annotations.set_shape([None, 5])\n",
    "        return image, annotations\n",
    "\n",
    "    dataset = dataset.map(normalize_with_shape, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "    def ensure_rgb_with_shape(image, annotations):\n",
    "        image, annotations = tf.py_function(\n",
    "            func=lambda img, ann: (ensure_rgb_format(img), ann),\n",
    "            inp=[image, annotations],\n",
    "            Tout=[tf.float32, tf.float32]\n",
    "        )\n",
    "        image.set_shape([224, 224, 3])\n",
    "        annotations.set_shape([None, 5])\n",
    "        return image, annotations\n",
    "\n",
    "    dataset = dataset.map(ensure_rgb_with_shape, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "    dataset = dataset.filter(lambda image, annotations: filter_empty_annotations(image, annotations))\n",
    "\n",
    "\n",
    "    dataset = dataset.map(lambda image, annotations: pad_annotations(image, annotations))\n",
    "\n",
    "    dataset = dataset.batch(batch_size, drop_remainder=False).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "b7b72f97-5958-4bac-9887-a37bd090f3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_dataset(dataset, value_range, default_rows, default_cols, bounding_box_format):\n",
    "    batch = next(iter(dataset.take(1)))\n",
    "\n",
    "    images, bounding_boxes_raw = batch\n",
    "\n",
    "    rows = default_rows\n",
    "    cols = default_cols\n",
    "\n",
    "    fig, axs = plt.subplots(rows, cols, figsize=(15, 15))\n",
    "    axs = axs.flatten() if rows * cols > 1 else [axs]\n",
    "\n",
    "    for ax, image, bboxes in zip(axs, images, bounding_boxes_raw):\n",
    "        ax.imshow(image, vmin=value_range[0], vmax=value_range[1])\n",
    "        for bbox in bboxes:\n",
    "            if tf.reduce_all(bbox != -1):\n",
    "                x_min, y_min, x_max, y_max, _ = bbox\n",
    "                rect = patches.Rectangle((x_min, y_min), x_max - x_min, y_max - y_min, linewidth=2, edgecolor='r', facecolor='none')\n",
    "                ax.add_patch(rect)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "84af5ea1-f503-408c-8ee4-b89a7be5af3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets for training, validation, and testing\n",
    "train_dataset = data_loader(TRAIN_IMAGES_DIR, TRAIN_LABELS_DIR, BATCH_SIZE)\n",
    "val_dataset = data_loader(VAL_IMAGES_DIR, VAL_LABELS_DIR, BATCH_SIZE // 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "f33b5946-d749-42dc-8061-0c791f1ddf21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: (640, 640, 3), Annotations: [[179.3936    3.87872 432.4848  864.9699    0.     ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[ 22.63264 113.6096  226.32608 340.8288    0.     ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[219.60768  89.41184 387.97375 581.96094   0.     ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[ 24.66016   4.66624 573.064   325.33313   0.     ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[ 21.96096   7.32    607.0592  404.7056    0.     ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[  6.27456   3.09952 638.9542  946.8282    0.     ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[ 78.43136   7.32    619.60767 413.0717    0.     ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[ 95.68608  15.6864  487.84286 325.2288    0.     ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[138.07584  94.11744 557.9011  312.67935   0.     ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[ 20.9152  130.83711 215.42528 324.72897   0.     ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[269.0003   26.66688 394.      700.4448    0.     ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[158.95456   6.28992 542.7453  816.11774   0.     ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[170.98016  15.6864  495.68607 330.4576    0.     ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[ 79.328    10.4576  588.90753 458.03903   0.     ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[ 22.85728  10.45728 610.6122  391.11072   0.     ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[169.41151  15.68672 564.7056  376.47073   0.     ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[ 21.96096 140.13055 249.41183 166.27457   0.     ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[366.01312 197.64703 446.536   669.80383   0.     ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[353.464   185.09824 437.12415 655.6864    0.     ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[314.24    45.0976 599.04   898.1114   0.    ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[109.80416  41.82976 580.39233 386.928     0.     ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[  6.27456  12.8     624.3136  955.2       0.     ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[193.18529   5.33344 480.      720.0003    0.     ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[ 44.61536  13.59456 613.84607 417.25473   0.     ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[220.65376  12.54912 430.8496  646.27454   0.     ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[ 23.00672  47.05888 160.      240.00032   0.     ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[234.79263   1.89376 459.48703 689.2307    0.     ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[ 22.85696   3.13696 636.73474 407.84286   0.     ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[ 56.28128  38.6928  623.9197  405.75137   0.     ]]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__IteratorGetNext_output_types_3_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes at component 0: expected [?,224,224,3] but got [3,640,640,3]. [Op:IteratorGetNext] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[219], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mannotations\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mImage shape:\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBoxes shape:\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mannotations\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mboxes\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\miniconda\\envs\\object_detection\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:809\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    807\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    808\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 809\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    810\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOutOfRangeError:\n\u001b[0;32m    811\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mD:\\miniconda\\envs\\object_detection\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:772\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    769\u001b[0m \u001b[38;5;66;03m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001b[39;00m\n\u001b[0;32m    770\u001b[0m \u001b[38;5;66;03m# to communicate that there is no more data to iterate over.\u001b[39;00m\n\u001b[0;32m    771\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecution_mode(context\u001b[38;5;241m.\u001b[39mSYNC):\n\u001b[1;32m--> 772\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator_get_next\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    773\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    774\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    775\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_shapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    777\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    778\u001b[0m     \u001b[38;5;66;03m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n\u001b[0;32m    779\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_element_spec\u001b[38;5;241m.\u001b[39m_from_compatible_tensor_list(ret)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32mD:\\miniconda\\envs\\object_detection\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:3086\u001b[0m, in \u001b[0;36miterator_get_next\u001b[1;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[0;32m   3084\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m   3085\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 3086\u001b[0m   \u001b[43m_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from_not_ok_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3087\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_FallbackException:\n\u001b[0;32m   3088\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32mD:\\miniconda\\envs\\object_detection\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:5983\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   5981\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[0;32m   5982\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m-> 5983\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__IteratorGetNext_output_types_3_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes at component 0: expected [?,224,224,3] but got [3,640,640,3]. [Op:IteratorGetNext] name: "
     ]
    }
   ],
   "source": [
    "for image, annotations in train_dataset.take(1):\n",
    "    print(\"Image shape:\", image.shape)\n",
    "    print(\"Boxes shape:\", annotations['boxes'].shape)\n",
    "    print(\"Classes shape:\", annotations['classes'].shape)\n",
    "    print(\"Boxes:\", annotations['boxes'])\n",
    "    print(\"Classes:\", annotations['classes'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "ec0a006c-f8e3-46e0-8060-81f67b7b0988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: (640, 640, 3), Annotations: [[179.3936    3.87872 432.4848  864.9699    0.     ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[ 22.63264 113.6096  226.32608 340.8288    0.     ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[ 24.66016   4.66624 573.064   325.33313   0.     ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[  6.27456   3.09952 638.9542  946.8282    0.     ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[219.60768  89.41184 387.97375 581.96094   0.     ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[ 21.96096   7.32    607.0592  404.7056    0.     ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[ 78.43136   7.32    619.60767 413.0717    0.     ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[ 20.9152  130.83711 215.42528 324.72897   0.     ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[ 95.68608  15.6864  487.84286 325.2288    0.     ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[138.07584  94.11744 557.9011  312.67935   0.     ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[269.0003   26.66688 394.      700.4448    0.     ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[158.95456   6.28992 542.7453  816.11774   0.     ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[170.98016  15.6864  495.68607 330.4576    0.     ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[ 22.85728  10.45728 610.6122  391.11072   0.     ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[169.41151  15.68672 564.7056  376.47073   0.     ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[ 21.96096 140.13055 249.41183 166.27457   0.     ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[ 79.328    10.4576  588.90753 458.03903   0.     ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[353.464   185.09824 437.12415 655.6864    0.     ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[314.24    45.0976 599.04   898.1114   0.    ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[  6.27456  12.8     624.3136  955.2       0.     ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[109.80416  41.82976 580.39233 386.928     0.     ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[366.01312 197.64703 446.536   669.80383   0.     ]]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__IteratorGetNext_output_types_3_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes at component 0: expected [?,224,224,3] but got [3,640,640,3]. [Op:IteratorGetNext] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[220], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Visualize the dataset\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mvisualize_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_rows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_cols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounding_box_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mxyxy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[217], line 2\u001b[0m, in \u001b[0;36mvisualize_dataset\u001b[1;34m(dataset, value_range, default_rows, default_cols, bounding_box_format)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvisualize_dataset\u001b[39m(dataset, value_range, default_rows, default_cols, bounding_box_format):\n\u001b[1;32m----> 2\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     images, bounding_boxes_raw \u001b[38;5;241m=\u001b[39m batch\n\u001b[0;32m      6\u001b[0m     rows \u001b[38;5;241m=\u001b[39m default_rows\n",
      "File \u001b[1;32mD:\\miniconda\\envs\\object_detection\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:809\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    807\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    808\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 809\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    810\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOutOfRangeError:\n\u001b[0;32m    811\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mD:\\miniconda\\envs\\object_detection\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:772\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    769\u001b[0m \u001b[38;5;66;03m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001b[39;00m\n\u001b[0;32m    770\u001b[0m \u001b[38;5;66;03m# to communicate that there is no more data to iterate over.\u001b[39;00m\n\u001b[0;32m    771\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecution_mode(context\u001b[38;5;241m.\u001b[39mSYNC):\n\u001b[1;32m--> 772\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator_get_next\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    773\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    774\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    775\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_shapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    777\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    778\u001b[0m     \u001b[38;5;66;03m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n\u001b[0;32m    779\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_element_spec\u001b[38;5;241m.\u001b[39m_from_compatible_tensor_list(ret)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32mD:\\miniconda\\envs\\object_detection\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:3086\u001b[0m, in \u001b[0;36miterator_get_next\u001b[1;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[0;32m   3084\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m   3085\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 3086\u001b[0m   \u001b[43m_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from_not_ok_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3087\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_FallbackException:\n\u001b[0;32m   3088\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32mD:\\miniconda\\envs\\object_detection\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:5983\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   5981\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[0;32m   5982\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m-> 5983\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__IteratorGetNext_output_types_3_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes at component 0: expected [?,224,224,3] but got [3,640,640,3]. [Op:IteratorGetNext] name: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: (640, 640, 3), Annotations: [[193.18529   5.33344 480.      720.0003    0.     ]]\n"
     ]
    }
   ],
   "source": [
    "# Visualize the dataset\n",
    "visualize_dataset(train_dataset, value_range=(0, 1), default_rows=1, default_cols=1, bounding_box_format=\"xyxy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "6f7dc7ef-82e3-4a7b-9928-9bf57e9ed6e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: (640, 640, 3), Annotations: [[172.5488    6.27424 401.56833 602.35297   0.     ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[104.3616   45.44416 250.21632 376.8048    0.     ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[ 70.41248   5.664   632.456   949.61664   0.     ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[ 10.98048 174.64032 155.29408 103.52928   0.     ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[180.91489  10.98016 611.7648  917.64703   0.     ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[189.28064   1.57632 385.88223 581.67487   0.     ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[ 37.64736   2.09184 560.      373.33344   0.     ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[2.2274529e+02 3.1999999e-04 4.8941217e+02 6.8383582e+02 0.0000000e+00]]\n",
      "Image shape: (640, 640, 3), Annotations: [[100.68992  35.55584 477.2416  361.8304    0.     ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[367.05887 191.3728  441.3072  661.96094   0.     ]]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__IteratorGetNext_output_types_3_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes at component 0: expected [?,224,224,3] but got [1,640,640,3]. [Op:IteratorGetNext] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[221], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mvisualize_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_rows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_cols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounding_box_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mxywh\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[217], line 2\u001b[0m, in \u001b[0;36mvisualize_dataset\u001b[1;34m(dataset, value_range, default_rows, default_cols, bounding_box_format)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvisualize_dataset\u001b[39m(dataset, value_range, default_rows, default_cols, bounding_box_format):\n\u001b[1;32m----> 2\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     images, bounding_boxes_raw \u001b[38;5;241m=\u001b[39m batch\n\u001b[0;32m      6\u001b[0m     rows \u001b[38;5;241m=\u001b[39m default_rows\n",
      "File \u001b[1;32mD:\\miniconda\\envs\\object_detection\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:809\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    807\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    808\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 809\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    810\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOutOfRangeError:\n\u001b[0;32m    811\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mD:\\miniconda\\envs\\object_detection\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:772\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    769\u001b[0m \u001b[38;5;66;03m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001b[39;00m\n\u001b[0;32m    770\u001b[0m \u001b[38;5;66;03m# to communicate that there is no more data to iterate over.\u001b[39;00m\n\u001b[0;32m    771\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecution_mode(context\u001b[38;5;241m.\u001b[39mSYNC):\n\u001b[1;32m--> 772\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator_get_next\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    773\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    774\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    775\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_shapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    777\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    778\u001b[0m     \u001b[38;5;66;03m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n\u001b[0;32m    779\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_element_spec\u001b[38;5;241m.\u001b[39m_from_compatible_tensor_list(ret)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32mD:\\miniconda\\envs\\object_detection\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:3086\u001b[0m, in \u001b[0;36miterator_get_next\u001b[1;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[0;32m   3084\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m   3085\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 3086\u001b[0m   \u001b[43m_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from_not_ok_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3087\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_FallbackException:\n\u001b[0;32m   3088\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32mD:\\miniconda\\envs\\object_detection\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:5983\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   5981\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[0;32m   5982\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m-> 5983\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__IteratorGetNext_output_types_3_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes at component 0: expected [?,224,224,3] but got [1,640,640,3]. [Op:IteratorGetNext] name: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: (640, 640, 3), Annotations: [[285.53888 194.06271 384.93793 256.56256   0.     ]\n",
      " [275.69217 333.12512 386.8128  257.81247   0.     ]]\n"
     ]
    }
   ],
   "source": [
    "visualize_dataset(val_dataset, value_range=(0, 1), default_rows=1, default_cols=1, bounding_box_format=\"xywh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0be0e4-f1d0-4f7e-b3cc-be88d50c37b0",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "1282ed9d-c3f8-4c92-a181-77093e3d1c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: (640, 640, 3), Annotations: [[179.3936    3.87872 432.4848  864.9699    0.     ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[ 22.63264 113.6096  226.32608 340.8288    0.     ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[ 24.66016   4.66624 573.064   325.33313   0.     ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[219.60768  89.41184 387.97375 581.96094   0.     ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[ 95.68608  15.6864  487.84286 325.2288    0.     ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[ 21.96096   7.32    607.0592  404.7056    0.     ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[ 78.43136   7.32    619.60767 413.0717    0.     ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[ 20.9152  130.83711 215.42528 324.72897   0.     ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[  6.27456   3.09952 638.9542  946.8282    0.     ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[269.0003   26.66688 394.      700.4448    0.     ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[138.07584  94.11744 557.9011  312.67935   0.     ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[170.98016  15.6864  495.68607 330.4576    0.     ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[169.41151  15.68672 564.7056  376.47073   0.     ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[353.464   185.09824 437.12415 655.6864    0.     ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[ 21.96096 140.13055 249.41183 166.27457   0.     ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[ 79.328    10.4576  588.90753 458.03903   0.     ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[158.95456   6.28992 542.7453  816.11774   0.     ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[314.24    45.0976 599.04   898.1114   0.    ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[109.80416  41.82976 580.39233 386.928     0.     ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[ 22.85728  10.45728 610.6122  391.11072   0.     ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[220.65376  12.54912 430.8496  646.27454   0.     ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[366.01312 197.64703 446.536   669.80383   0.     ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[234.79263   1.89376 459.48703 689.2307    0.     ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[ 22.85696   3.13696 636.73474 407.84286   0.     ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[193.18529   5.33344 480.      720.0003    0.     ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[ 44.61536  13.59456 613.84607 417.25473   0.     ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[  6.27456  12.8     624.3136  955.2       0.     ]]\n",
      "Image shape: (640, 640, 3), Annotations: [[ 23.00672  47.05888 160.      240.00032   0.     ]]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__IteratorGetNext_output_types_3_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes at component 0: expected [?,224,224,3] but got [3,640,640,3]. [Op:IteratorGetNext] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[224], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mannotations\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mImage shape:\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAnnotations:\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mannotations\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\miniconda\\envs\\object_detection\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:809\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    807\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    808\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 809\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    810\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOutOfRangeError:\n\u001b[0;32m    811\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mD:\\miniconda\\envs\\object_detection\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:772\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    769\u001b[0m \u001b[38;5;66;03m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001b[39;00m\n\u001b[0;32m    770\u001b[0m \u001b[38;5;66;03m# to communicate that there is no more data to iterate over.\u001b[39;00m\n\u001b[0;32m    771\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecution_mode(context\u001b[38;5;241m.\u001b[39mSYNC):\n\u001b[1;32m--> 772\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator_get_next\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    773\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    774\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    775\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_shapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    777\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    778\u001b[0m     \u001b[38;5;66;03m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n\u001b[0;32m    779\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_element_spec\u001b[38;5;241m.\u001b[39m_from_compatible_tensor_list(ret)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32mD:\\miniconda\\envs\\object_detection\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:3086\u001b[0m, in \u001b[0;36miterator_get_next\u001b[1;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[0;32m   3084\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m   3085\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 3086\u001b[0m   \u001b[43m_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from_not_ok_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3087\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_FallbackException:\n\u001b[0;32m   3088\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32mD:\\miniconda\\envs\\object_detection\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:5983\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   5981\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[0;32m   5982\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m-> 5983\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__IteratorGetNext_output_types_3_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes at component 0: expected [?,224,224,3] but got [3,640,640,3]. [Op:IteratorGetNext] name: "
     ]
    }
   ],
   "source": [
    "for image, annotations in train_dataset.take(1):\n",
    "    print(\"Image shape:\", image.shape)\n",
    "    print(\"Annotations:\", annotations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "919c4499-2177-4809-9412-7b66b3d7eba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_lr = 0.005\n",
    "# including a global_clipnorm is extremely important in object detection tasks\n",
    "optimizer = keras.optimizers.SGD(\n",
    "    learning_rate=base_lr, momentum=0.9, global_clipnorm=10.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "c18a0f0b-f9c4-46ef-8baf-39b78aa966de",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = keras_cv.models.YOLOV8Detector.from_preset(\n",
    "    \"yolo_v8_m_pascalvoc\", bounding_box_format=\"xywh\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "b965a862-00b0-457c-9b34-1d9846ca4e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model.compile(\n",
    "    classification_loss=\"binary_crossentropy\",\n",
    "    box_loss=\"ciou\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "d97e39ce-151a-43a3-8b1a-5a66af120b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_metrics_callback = keras_cv.callbacks.PyCOCOCallback(\n",
    "    val_dataset.take(20), bounding_box_format=\"xywh\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b603f09-42ef-4843-b031-d5295d552b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras_cv.models.YOLOV8Detector.from_preset(\n",
    "    \"resnet50_imagenet\",\n",
    "    # For more info on supported bounding box formats, visit\n",
    "    # https://keras.io/api/keras_cv/bounding_box/\n",
    "    bounding_box_format=\"xywh\",\n",
    "    num_classes=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c5e1b5-907f-414f-8f06-f5518073da93",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    classification_loss=\"binary_crossentropy\",\n",
    "    box_loss=\"ciou\",\n",
    "    optimizer=optimizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9972375a-5281-41e3-9bbc-9061eafcd177",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    train_dataset.take(20),\n",
    "    # Run for 10-35~ epochs to achieve good scores.\n",
    "    epochs=1,\n",
    "    callbacks=[coco_metrics_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6c87d7-5e2d-4202-9b5a-39f8c608d9ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
